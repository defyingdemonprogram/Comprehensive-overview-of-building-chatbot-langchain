{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc46651b-dab7-42a8-9fc4-434e5a58eba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sanjeev/Desktop/Trainee/Comprehensive-overview-of-building-chatbot-langchain/Similarity Search/similarity/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcfa12a-ee42-4260-974b-bb6c47bf2d9c",
   "metadata": {},
   "source": [
    "## Data Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2420778c-a013-4408-8a06-f6b2fbbe0057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pair_ID\tsentence_A\tsentence_B\trelatedness_score\tentailment_judgment\n",
      "1\tA group of kids is playing in \n"
     ]
    }
   ],
   "source": [
    "res = requests.get('https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/sick2014/SICK_train.txt')\n",
    "\n",
    "text = res.text\n",
    "# print sample text\n",
    "print(text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7d72e6e-1cc6-4e78-8ecc-6ccd3bf4bc22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe:  (4500, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair_ID</th>\n",
       "      <th>sentence_A</th>\n",
       "      <th>sentence_B</th>\n",
       "      <th>relatedness_score</th>\n",
       "      <th>entailment_judgment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A group of kids is playing in a yard and an ol...</td>\n",
       "      <td>A group of boys in a yard is playing and a man...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A group of children is playing in the house an...</td>\n",
       "      <td>A group of kids is playing in a yard and an ol...</td>\n",
       "      <td>3.2</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>The young boys are playing outdoors and the ma...</td>\n",
       "      <td>The kids are playing outdoors near a man with ...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>ENTAILMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>The kids are playing outdoors near a man with ...</td>\n",
       "      <td>A group of kids is playing in a yard and an ol...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>The young boys are playing outdoors and the ma...</td>\n",
       "      <td>A group of kids is playing in a yard and an ol...</td>\n",
       "      <td>3.7</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pair_ID                                         sentence_A  \\\n",
       "0        1  A group of kids is playing in a yard and an ol...   \n",
       "1        2  A group of children is playing in the house an...   \n",
       "2        3  The young boys are playing outdoors and the ma...   \n",
       "3        5  The kids are playing outdoors near a man with ...   \n",
       "4        9  The young boys are playing outdoors and the ma...   \n",
       "\n",
       "                                          sentence_B  relatedness_score  \\\n",
       "0  A group of boys in a yard is playing and a man...                4.5   \n",
       "1  A group of kids is playing in a yard and an ol...                3.2   \n",
       "2  The kids are playing outdoors near a man with ...                4.7   \n",
       "3  A group of kids is playing in a yard and an ol...                3.4   \n",
       "4  A group of kids is playing in a yard and an ol...                3.7   \n",
       "\n",
       "  entailment_judgment  \n",
       "0             NEUTRAL  \n",
       "1             NEUTRAL  \n",
       "2          ENTAILMENT  \n",
       "3             NEUTRAL  \n",
       "4             NEUTRAL  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data is in tabulare format\n",
    "# convert the text into dataframe\n",
    "data = pd.read_csv(StringIO(text), sep=\"\\t\")\n",
    "print(\"Shape of dataframe: \", data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e0c4575-f05f-4c01-bcfe-9a201d7d63cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentence in list: 9000\n",
      "Total unique sentence in list: 4802\n"
     ]
    }
   ],
   "source": [
    "# append both sentences and sentences 2 in a single list\n",
    "sentences = data[\"sentence_A\"].tolist()\n",
    "sentences_b = data[\"sentence_B\"].tolist()\n",
    "\n",
    "# make it in single list\n",
    "sentences.extend(sentences_b)\n",
    "print(\"Total sentence in list: {}\".format(len(sentences)))\n",
    "print(\"Total unique sentence in list: {}\".format(len(set(sentences))))      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109ed66c-a72e-4d00-af9a-f9e64a4bc9ff",
   "metadata": {},
   "source": [
    "## Get more dimilar datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07ab4a4c-a010-4c30-8a91-629be088a360",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2012/MSRpar.train.tsv',\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2012/MSRpar.test.tsv',\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2012/OnWN.test.tsv',\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2013/OnWN.test.tsv',\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2014/OnWN.test.tsv',\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2014/images.test.tsv',\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2015/images.test.tsv'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d38099af-7697-42a7-bfd6-102a16992237",
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in urls:\n",
    "    res = requests.get(url)\n",
    "    # extract data to dataframe similar to above\n",
    "    data = pd.read_csv(StringIO(res.text), sep='\\t', header=None, on_bad_lines=\"skip\")\n",
    "    # add columns 1 and 2 in sentences list\n",
    "    sentences.extend(data[1].tolist())\n",
    "    sentences.extend(data[2].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76f3f036-5de9-4ee9-87dd-b4ab3fd1c552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total senteces: 20470\n",
      "Unique senteces: 14505\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total senteces: {len(sentences)}\")\n",
    "print(f\"Unique senteces: {len(set(sentences))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf2cda65-2b23-4500-91b8-6580af3b6c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tota sentence ready for embeddings: 14504\n"
     ]
    }
   ],
   "source": [
    "# before embedding remove duplicates\n",
    "sentences = [\n",
    "    sentence.replace(\"\\n\", \"\") for sentence in list(set(sentences)) if type(sentence) is str\n",
    "]\n",
    "# now total sentence we have\n",
    "print(f\"Tota sentence ready for embeddings: {len(sentences)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "704f24c8-8aeb-485b-9578-1ea00cc52c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# secure copy of unique senteces in local file\n",
    "with open(\"sentences.txt\", \"w\") as fp:\n",
    "    fp.write(\"\\n\".join(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cc1633-53cf-4308-b6f9-7a4a40f7edfe",
   "metadata": {},
   "source": [
    "## Build the Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20fd76f5-da76-43ec-9df7-9274aeb9297a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sanjeev/Desktop/Trainee/Comprehensive-overview-of-building-chatbot-langchain/Similarity Search/similarity/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14504, 768)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SentenceTransformer(\"bert-base-nli-mean-tokens\")\n",
    "\n",
    "sentence_embeddings = model.encode(sentences)\n",
    "sentence_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63b737c1-428e-41aa-834b-8d50a3c29680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings 00.npy | 0 -> 256\n",
      "Embeddings 01.npy | 256 -> 512\n",
      "Embeddings 02.npy | 512 -> 768\n",
      "Embeddings 03.npy | 768 -> 1024\n",
      "Embeddings 04.npy | 1024 -> 1280\n",
      "Embeddings 05.npy | 1280 -> 1536\n",
      "Embeddings 06.npy | 1536 -> 1792\n",
      "Embeddings 07.npy | 1792 -> 2048\n",
      "Embeddings 08.npy | 2048 -> 2304\n",
      "Embeddings 09.npy | 2304 -> 2560\n",
      "Embeddings 10.npy | 2560 -> 2816\n",
      "Embeddings 11.npy | 2816 -> 3072\n",
      "Embeddings 12.npy | 3072 -> 3328\n",
      "Embeddings 13.npy | 3328 -> 3584\n",
      "Embeddings 14.npy | 3584 -> 3840\n",
      "Embeddings 15.npy | 3840 -> 4096\n",
      "Embeddings 16.npy | 4096 -> 4352\n",
      "Embeddings 17.npy | 4352 -> 4608\n",
      "Embeddings 18.npy | 4608 -> 4864\n",
      "Embeddings 19.npy | 4864 -> 5120\n",
      "Embeddings 20.npy | 5120 -> 5376\n",
      "Embeddings 21.npy | 5376 -> 5632\n",
      "Embeddings 22.npy | 5632 -> 5888\n",
      "Embeddings 23.npy | 5888 -> 6144\n",
      "Embeddings 24.npy | 6144 -> 6400\n",
      "Embeddings 25.npy | 6400 -> 6656\n",
      "Embeddings 26.npy | 6656 -> 6912\n",
      "Embeddings 27.npy | 6912 -> 7168\n",
      "Embeddings 28.npy | 7168 -> 7424\n",
      "Embeddings 29.npy | 7424 -> 7680\n",
      "Embeddings 30.npy | 7680 -> 7936\n",
      "Embeddings 31.npy | 7936 -> 8192\n",
      "Embeddings 32.npy | 8192 -> 8448\n",
      "Embeddings 33.npy | 8448 -> 8704\n",
      "Embeddings 34.npy | 8704 -> 8960\n",
      "Embeddings 35.npy | 8960 -> 9216\n",
      "Embeddings 36.npy | 9216 -> 9472\n",
      "Embeddings 37.npy | 9472 -> 9728\n",
      "Embeddings 38.npy | 9728 -> 9984\n",
      "Embeddings 39.npy | 9984 -> 10240\n",
      "Embeddings 40.npy | 10240 -> 10496\n",
      "Embeddings 41.npy | 10496 -> 10752\n",
      "Embeddings 42.npy | 10752 -> 11008\n",
      "Embeddings 43.npy | 11008 -> 11264\n",
      "Embeddings 44.npy | 11264 -> 11520\n",
      "Embeddings 45.npy | 11520 -> 11776\n",
      "Embeddings 46.npy | 11776 -> 12032\n",
      "Embeddings 47.npy | 12032 -> 12288\n",
      "Embeddings 48.npy | 12288 -> 12544\n",
      "Embeddings 49.npy | 12544 -> 12800\n",
      "Embeddings 50.npy | 12800 -> 13056\n",
      "Embeddings 51.npy | 13056 -> 13312\n",
      "Embeddings 52.npy | 13312 -> 13568\n",
      "Embeddings 53.npy | 13568 -> 13824\n",
      "Embeddings 54.npy | 13824 -> 14080\n",
      "Embeddings 55.npy | 14080 -> 14336\n",
      "Embeddings 56.npy | 14336 -> 14505\n"
     ]
    }
   ],
   "source": [
    "directory = \"sim_sentences\"\n",
    "# Create the directory if it does not exist\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# saving embeddings for future use\n",
    "split = 256\n",
    "file_count = 0\n",
    "for i in range(0, sentence_embeddings.shape[0], split):\n",
    "    end = i + split\n",
    "    if end > sentence_embeddings.shape[0] + 1:\n",
    "        end = sentence_embeddings.shape[0] + 1\n",
    "    \n",
    "    file_count_str = \"0\" + str(file_count) if file_count < 10 else str(file_count)\n",
    "    with open(f\"./sim_sentences/embeddings_{file_count_str}.npy\", \"wb\") as fp:\n",
    "        np.save(fp, sentence_embeddings[i:end, :])\n",
    "    print(f\"Embeddings {file_count_str}.npy | {i} -> {end}\")\n",
    "    file_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d48b70e-9664-40fc-9668-ec7c92c90da4",
   "metadata": {},
   "source": [
    "## Setup FAISS database dimensionality(number of dimensions per vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c97e34a4-8385-4f4d-877a-ea37f026ad9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = sentence_embeddings.shape[1]\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02bc233-e221-4bd9-8670-a3e22b997b7a",
   "metadata": {},
   "source": [
    "## Flat L2 Index Initialization\n",
    "\n",
    "To initialize the flat L2 distance (Euclidean distance) index `IndexFlatL2`, we only need to specify the vector dimensionality, which in this case is `d=768`, to align with the Sentence-BERT model output embeddings of size 768."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bf9d3af-8ead-46d5-a3be-3515411855ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.IndexFlatL2(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63743627-3903-4b31-bc66-44d0341e1c54",
   "metadata": {},
   "source": [
    "Frequently, we utilize indexes that necessitate training on our data before utilization, particularly if we are grouping or transforming the data. However, with `IndexFlatL2`, it's a straightforward operation that only entails calculating distances between vectors when introducing our query vector $x_q$ during search. Hence, in this scenario, no training is necessary. We can verify this by checking the `is_trained` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e0d97b8-f480-4799-9024-340281c66d9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.is_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4472522c-6610-4c67-8b0d-bd52499f8f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total index: 14504\n"
     ]
    }
   ],
   "source": [
    "# we can add vectors in index using `add` method\n",
    "index.add(sentence_embeddings)\n",
    "print(f\"Total index: {index.ntotal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5943e700-38ba-4153-9046-f0a5bdeef478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search the give query\n",
    "query = \"Someone sprints with a football in field\"\n",
    "xq = model.encode([query])\n",
    "\n",
    "# total result to retrive\n",
    "k = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41516b15-957d-4ae4-89cc-7f59bdd263e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3124 1290 2541 9430]]\n",
      "CPU times: user 3.45 ms, sys: 1.08 ms, total: 4.52 ms\n",
      "Wall time: 4.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "distance, idxs_from_flan_v2 = index.search(xq, k)\n",
    "print(idxs_from_flan_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5e77097-976e-4a25-bffd-0b855169be14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3124: A group of football players is running in the field',\n",
       " '1290: A group of people playing football is running in the field',\n",
       " '2541: A group of football players running down the field.',\n",
       " '9430: Football players are on the field.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the document retrived\n",
    "doc_retrive_flan_l2 = [f\"{i}: {sentences[i]}\" for i in idxs_from_flan_v2[0]]\n",
    "doc_retrive_flan_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d26884fa-b2cd-45c7-99ed-ef40ba0c30f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of vecs:  (4, 768)\n"
     ]
    }
   ],
   "source": [
    "# we can also extract embedding vector fropm the FAISS\n",
    "vecs = np.zeros((k, d))\n",
    "for i, val in enumerate(idxs_from_flan_v2[0].tolist()):\n",
    "    vecs[i, :] = index.reconstruct(val)\n",
    "\n",
    "print(\"Shape of vecs: \", vecs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14606d96-2782-405f-b7cf-d596ddbaba9f",
   "metadata": {},
   "source": [
    "<div style=\"display: flex;\">\n",
    "    <div style=\"flex: 1;\">\n",
    "        <h3>Adding Partitioning to the Index</h3>\n",
    "        <p><em>FAISS</em> allows us to <em>add an additional step</em> to optimize our search efficiency using a variety of different methods. A popular approach is to partition the index into <a href=\"https://en.wikipedia.org/wiki/Voronoi_diagram\">Voronoi cells</a>.</p>\n",
    "        <p>Using this method we would take our query vector \\( x_q \\), <strong>identify the cell it belongs to, and then use our <code>IndexFlatL2</code> to search between the query vector \\( x_q \\)</strong> and all indexed vectors belonging to that cell. We can also include vectors from other nearby cells too.</p>\n",
    "        <p>We initialize our new partitioned index by first adding our previous <code>IndexFlatL2</code> operation as a quantization step (another step in the search process), and feeding this into the new <code>IndexIVFFlat</code> operation like so:</p>\n",
    "    </div>\n",
    "    <div>\n",
    "        <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/5/54/Euclidean_Voronoi_diagram.svg/1024px-Euclidean_Voronoi_diagram.svg.png\" alt=\"Voronoi cells\" height=400 width=400>\n",
    "    </div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d074adb-e391-46c8-b8d9-a1eb8114446e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define number of cells we like to partitioned for index\n",
    "n_list = 50\n",
    "quantizer = faiss.IndexFlatL2(d)\n",
    "# initiate the index with quantizion(i.e, cell partioned)\n",
    "index = faiss.IndexIVFFlat(quantizer, d, n_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5dfda263-2702-490e-a7fc-47274b989ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we have added partioned in the index\n",
    "# we have to train it\n",
    "index.is_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de849402-dec1-4a95-a5a4-b7124df9c0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total index:  14504\n"
     ]
    }
   ],
   "source": [
    "# train our index in our data before adding data in index\n",
    "index.train(sentence_embeddings)\n",
    "\n",
    "# after training index, we add our data\n",
    "index.add(sentence_embeddings)\n",
    "print(\"Total index: \", index.ntotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "309ba3d3-ed10-48e0-9658-6187d4b12d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrived index:  [[3124 1290 2541 9430]]\n",
      "CPU times: user 19.4 ms, sys: 14 μs, total: 19.4 ms\n",
      "Wall time: 2.52 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "distance, idxs_from_ivfflat = index.search(xq, k)  # search\n",
    "print(\"Retrived index: \", idxs_from_ivfflat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f7749d-63a1-47ec-a951-308acc630fda",
   "metadata": {},
   "source": [
    "#### Increasing `nprobe`\n",
    "Increasing the **number of `nprobe` will improve the accuracy of our search, but cost time**. Our earlier `IndexFlatL2`-only search was exhaustive (it compared every single vector) and so it identified the closest matches with a perfect accuracy. The <strong>smaller our nprobe value, the smaller scope that we search</strong>. We received perfect results (that matched our previous `IndexFlatL2`-only results - `7460, 10940, 3781, 5747`), however, if we found that we were not getting closely matching results, we could simply bump `nprobe` up further - improving accuracy, but increasing time-taken too.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd0e7caa-b224-4503-967c-9611b5930463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how much cell to look when searching the doc\n",
    "index.nprobe = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72af1cee-3e1e-4cd7-8926-54466db4f12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrived index from 10 cells(more accurate):  [[3124 1290 2541 9430]]\n",
      "CPU times: user 1.3 ms, sys: 972 μs, total: 2.27 ms\n",
      "Wall time: 1.15 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "distance, idxs_from_ivfflat_nprob_10 = index.search(xq, k)\n",
    "print(\"Retrived index from 10 cells(more accurate): \", idxs_from_ivfflat_nprob_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b2b7b2e-13a6-4f7b-9f55-69c3eb0d538f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3124: A group of football players is running in the field',\n",
       " '1290: A group of people playing football is running in the field',\n",
       " '2541: A group of football players running down the field.',\n",
       " '9430: Football players are on the field.']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the document retrived\n",
    "doc_retrive_ivfflat = [f\"{i}: {sentences[i]}\" for i in idxs_from_ivfflat_nprob_10[0]]\n",
    "doc_retrive_ivfflat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2027219-b50c-4b54-9a57-ec588c62ae5a",
   "metadata": {},
   "source": [
    "### Reconstructing the index\n",
    "For IVF (and IMI) indexes, before attempting to use the `reconstruct` method, we need to call the `make_direct_map` method - otherwise we will return a `RunetimeError`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b1722d07-61b5-4b01-8dc5-d068fa0c7200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR]: Error in faiss::idx_t faiss::DirectMap::get(faiss::idx_t) const at /project/faiss/faiss/invlists/DirectMap.cpp:82: direct map not initialized\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    index.reconstruct(3)\n",
    "except Exception as err:\n",
    "    print(f\"[ERROR]: {err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e102bb4c-bca5-4b0f-9e27-36d99fde548f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768,)\n"
     ]
    }
   ],
   "source": [
    "# call `make_direct_map` method\n",
    "index.make_direct_map()\n",
    "# reconstruct the embedding from the index\n",
    "print(index.reconstruct(2).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547cc1d0-0c22-4a29-8b31-1d521cbfae96",
   "metadata": {},
   "source": [
    "### IndexIVFPQ(Product Quantization)\n",
    "In the above section, we store full vectors in `Flat`, which can become problematic with large datasets due to excessive space consumption.\n",
    "\n",
    "**FAISS** provides the capability to compress our vectors using transformations based on *Product Quantization (PQ)*. But, what exactly is PQ? You can think of it as an additional approximation step, similar to our use of IVF, which allowed us to approximate by narrowing down the search scope. However, PQ slightly differs and approximates the distance (or similarity) calculation instead.\n",
    "\n",
    "PQ achieves this by compressing the vectors themselves, involving several steps:\n",
    "\n",
    "1. We split each original vector into several subvectors.\n",
    "2. For each set of subvectors, we conduct a clustering operation, creating numerous centroids for each subvector set.\n",
    "3. In our vector of subvectors, we replace each subvector with the ID of its nearest centroid.\n",
    "\n",
    "[More about PQ](https://mccormickml.com/2017/10/13/product-quantizer-tutorial-part-1/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "340fb71b-7253-4ee0-816b-3b2370f4f27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of centroid IDs in final compressed vectrors\n",
    "m = 8\n",
    "# number of bits in each centroid\n",
    "bits = 8\n",
    "\n",
    "quantizer = faiss.IndexFlatL2(d)\n",
    "index = faiss.IndexIVFPQ(quantizer, d, n_list, m, bits) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "54b4a030-ef4e-4f55-ba8d-ee6ab6416e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index is_trained:  False\n"
     ]
    }
   ],
   "source": [
    "print(\"Index is_trained: \", index.is_trained)\n",
    "# train the indedx\n",
    "index.train(sentence_embeddings)\n",
    "\n",
    "# add the embedding in `index`\n",
    "index.add(sentence_embeddings)\n",
    "\n",
    "# nprobe 10\n",
    "index.nprobe = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "94952810-c61a-47ee-9ce8-82b423f070e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 137 1231 2431 2672]]\n",
      "CPU times: user 15.5 ms, sys: 1.01 ms, total: 16.5 ms\n",
      "Wall time: 2.38 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "distance, idxs_from_ivfpq = index.search(xq, k)\n",
    "print(idxs_from_ivfpq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee820c92-6c4a-4f5d-9236-ac6c83fa3597",
   "metadata": {},
   "source": [
    "### Difference in index\n",
    "Now, we should also notice the slightly different results being returned. Beforehand with our exhaustive L2 search we were returning `[10392 10474    34  6817]` from `IVF`. Now, we see a slightly different order to our results - and two different vectors, `[4344 5811 1963]`\n",
    "\n",
    "Each of our speed optimization operations, IVF and PQ, come at the cost of accuracy. Now, if we print out these results we will nonetheless find that each item is still a relevant match:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6bacc7f8-b881-4100-9843-379bdef544a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['137: The crowd is watching the football at the game',\n",
       " '1231: An Oklahoma football player attempts to kick the ball.',\n",
       " '2431: Three football players from red team tackling one player from white team.',\n",
       " '2672: Two boys are playing flag football.']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the document retrived\n",
    "doc_retrive_ivfpq = [f\"{i}: {sentences[i]}\" for i in idxs_from_ivfpq[0]]\n",
    "doc_retrive_ivfpq"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
